{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "#import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from IPython.core.display import clear_output, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ariadne.parsing import parse_df\n",
    "import ariadne.transformations  as trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_0  version_10  version_3  version_5  version_7\tversion_9\r\n",
      "version_1  version_2   version_4  version_6  version_8\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../lightning_logs/TrackNETv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = '/zfs/hybrilit.jinr.ru/user/n/nuvard/ariadne/ariadne/data/bmn_data/bmn_5.txt'\n",
    "csv_params={\n",
    "                    \"sep\": '\\s+',\n",
    "                    #\"nrows\": 500000,\n",
    "                    \"encoding\": 'utf-8',\n",
    "                    \"names\":  ['event',  'x', 'y', 'z', 'det','station', 'track', 'px', 'py', 'pz', 'vx', 'vy', 'vz']\n",
    "                 }\n",
    "df = parse_df(elem, **csv_params)\n",
    "#sns.set_style('darkgrid')\n",
    "grouped_df = df.groupby('event')\n",
    "num_hits = []\n",
    "num_tracks = []\n",
    "num_fakes = []\n",
    "one_event = None\n",
    "num = 163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ev_data in grouped_df:\n",
    "    if i > 0:\n",
    "        break\n",
    "    stations = ev_data.groupby('station').size().max()\n",
    "    #max_station = max(stations)\n",
    "    num_hits.append(stations)\n",
    "    num_fakes.append(len(ev_data[ev_data['track']==-1]))\n",
    "    num_tracks.append(ev_data[ev_data['track']!=-1].groupby('track').ngroups)\n",
    "max_num_hits = []\n",
    "num_events = []\n",
    "for i in range(1, len(num_hits)):\n",
    "    max_num_hits.append(np.max(num_hits[:i]))\n",
    "    num_events.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_event = df[df['event']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_values = {0:12.344, 1: 15.614, 2: 24.499, 3: 39.702, 4: 64.535, 5: 112.649, 6: 135.330,7: 160.6635, 8: 183.668}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_event.loc[one_event.det == 1, 'station'] = one_event.loc[one_event.det == 1, 'station'].values + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = trn.Compose([\n",
    "    trn.DropShort(num_stations=4),\n",
    "    trn.DropTracksWithHoles(),\n",
    "    trn.DropSpinningTracks(),\n",
    "    #@DropFakes(),\n",
    "    trn.BakeStationValues(values=z_values),]\n",
    "    #@ToCylindrical(),\n",
    "    #@ConstraintsNormalize(),\n",
    "   # @ToBuckets(),\n",
    ")\n",
    "\n",
    "transformed = transformer(one_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ariadne.utils.model import get_checkpoint_path, weights_update\n",
    "from ariadne.tracknet_v2.model import TrackNETv2\n",
    "from ariadne.tracknet_v2_1.model import TrackNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracknet_input_features=3\n",
    "tracknet_conv_features=32\n",
    "DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tracknet_ckpt_path_dict = {'model_dir': '/zfs/hybrilit.jinr.ru/user/d/drusov/ariadne/lightning_logs/TrackNETv2', \n",
    "                           'version': 'version_10', 'checkpoint': 'latest'}\n",
    "#classifier_ckpt_path_dict = {'model_dir': '/zfs/hybrilit.jinr.ru/user/n/nuvard/ariadne/lightning_logs/TrackNetClassifier', \n",
    "#                             'version': 'version_108', 'checkpoint': 'latest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackNETv2(\n",
       "  (conv): Sequential(\n",
       "    (0): CausalConv1d(3, 32, kernel_size=(3,), stride=(1,), padding=(2,), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (rnn): GRU(32, 32, num_layers=2, batch_first=True)\n",
       "  (xy_coords): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       "  (r1_r2): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_tracknet_ckpt = get_checkpoint_path(**tracknet_ckpt_path_dict)\n",
    "#path_to_classifier_ckpt = get_checkpoint_path(**classifier_ckpt_path_dict)\n",
    "\n",
    "model = weights_update(model=TrackNETv2(input_features=tracknet_input_features,\n",
    "                                        conv_features=tracknet_conv_features,\n",
    "                                        rnn_type='gru',\n",
    "                                        batch_first=True,\n",
    "                                        use_causalconv=True),\n",
    "                       checkpoint=torch.load(path_to_tracknet_ckpt, map_location=torch.device(DEVICE)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackNETv2(\n",
       "  (conv): Sequential(\n",
       "    (0): CausalConv1d(3, 32, kernel_size=(3,), stride=(1,), padding=(2,), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (rnn): GRU(32, 32, num_layers=2, batch_first=True)\n",
       "  (xy_coords): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       "  (r1_r2): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ariadne.utils.data import load_data\n",
    "from ariadne.utils.base import store_in_index,search_in_index\n",
    "from ariadne.graph_net.graph_utils.graph_prepare_utils import to_pandas_graph_from_df\n",
    "\n",
    "\n",
    "from ariadne.transformations import Compose, ConstraintsNormalize, ToCylindrical, DropSpinningTracks, DropShort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ariadne.utils.base import *\n",
    "from ariadne.utils.inference import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_seeds(hits, columns=['x','y','z']):\n",
    "    temp1 = hits[hits.station == 0]\n",
    "    st0_hits = hits[hits.station == 0][columns].values\n",
    "    temp2 = hits[hits.station == 1]\n",
    "    st1_hits = hits[hits.station == 1][columns].values\n",
    "    # all possible combinations\n",
    "    idx0 = range(len(st0_hits))\n",
    "    idx1 = range(len(st1_hits))\n",
    "    idx_comb = itertools.product(idx0, idx1)\n",
    "    # unpack indices\n",
    "    idx0, idx1 = zip(*idx_comb)\n",
    "    idx0 = list(idx0)\n",
    "    idx1 = list(idx1)\n",
    "    # create seeds array\n",
    "    seeds = np.zeros((len(idx0), 2, 3))\n",
    "    seeds[:, 0, ] = st0_hits[idx0]\n",
    "    seeds[:, 1, ] = st1_hits[idx1]\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_columns=('x', 'y', 'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hits_in_ellipses(ellipses, nearest_hits, hits_index, z_last=True, filter_station=True, find_n=10):\n",
    "    \"\"\"Function to get hits, which are in given ellipse.\n",
    "    Space is 3-dimentional, so either first component of ellipce must be z-coordinate or third.\n",
    "    Ellipse semiaxises must include x- and y-axis.\n",
    "    Arguments:\n",
    "        ellipse (np.array of size 5): predicted index with z-component like\n",
    "                                      (x,y,z, x-semiaxis, y_semiaxis) or (z, x,y, x-semiaxis, y_semiaxis)\n",
    "        nearest_hits (np.array of shape (n_hits, 3) or only 3): some hits in 3-dim space\n",
    "        z_last (bool): If True, first component of vector is interpreted as z, if other, third.\n",
    "        filter_station (bool): if True, only hits with same z-coordinate are considered, else all hits\n",
    "    Returns:\n",
    "        numpy.ndarry with filtered hits, all of them in given ellipse, sorted by increasing of distance\n",
    "    \"\"\"\n",
    "    assert nearest_hits.shape[-1] == 3, \"index is 3-dimentional, please add z-coordinate to centers\"\n",
    "    if nearest_hits.ndim < 2:\n",
    "        nearest_hits = np.expand_dims(nearest_hits, 0)\n",
    "    if nearest_hits.ndim < 3:\n",
    "        nearest_hits = np.expand_dims(nearest_hits, 0)\n",
    "    assert ellipses.shape[-1] == 5, \"index is 3-dimentional, you need to provide z-coordinate (z_c, x_c, y_c, x_r, y_r) or (x_c, y_c, z_c, x_r, y_r)\"\n",
    "    #ellipses = np.expand_dims(ellipses, -1)\n",
    "    #find_n = len(nearest_hits)\n",
    "    ellipses = np.expand_dims(ellipses, 2)\n",
    "    #found_hits = nearest_hits.reshape(-1, find_n, nearest_hits.shape[-1])\n",
    "    if z_last:\n",
    "        x_part = (ellipses[:,0].repeat(find_n,1) - nearest_hits[:, :, 0]) / ellipses[:, 3].repeat(find_n,1)\n",
    "        #print(x_part**2)\n",
    "        y_part = (ellipses[:,1].repeat(find_n,1) - nearest_hits[:, :, 1]) / ellipses[:, 4].repeat(find_n,1)\n",
    "        #print(y_part**2)\n",
    "    else:\n",
    "        x_part = (nearest_hits[:, :, 1] - ellipses[:, 1].repeat(find_n, 1)) / ellipses[:, -2].repeat(find_n, 1)\n",
    "        y_part = (nearest_hits[:, :, 2] - ellipses[:, 2].repeat(find_n, 1)) / ellipses[:, -1].repeat(find_n, 1)\n",
    "    left_side = x_part**2 + y_part**2\n",
    "    is_in_ellipse = left_side <= 1\n",
    "    is_in_ellipse *= hits_index != -1\n",
    "    return nearest_hits, is_in_ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COMPONENTS = 2\n",
    "SUFX = ['_p', '_c']\n",
    "COLS = ['x', 'y', 'z']\n",
    "\n",
    "def build_index(target_df):\n",
    "    cont = np.ascontiguousarray(target_df[COLS].values)\n",
    "    return store_in_index(cont)\n",
    "\n",
    "def build_hits(target_df):\n",
    "    cont = np.ascontiguousarray(target_df[COLS].values)\n",
    "    return cont\n",
    "\n",
    "def search(points, index):\n",
    "    cont = np.ascontiguousarray(points[COLS].values)\n",
    "    return search_in_index(cont, index, 10, n_dim=3)\n",
    "\n",
    "def to_cart(df):\n",
    "    graph=to_pandas_graph_from_df(df,SUFX, save_index=False)\n",
    "    seeds = graph[(graph.station_p == 0) & (graph.station_c == 1)]\n",
    "    target = df[df.station == 2]\n",
    "    return seeds, target\n",
    "\n",
    "def seeds_to_input(seeds_df):\n",
    "    return seeds_df[['x_p', 'y_p', 'z_p', 'x_c', 'y_c', 'z_c']].values.reshape((-1, 2, 3))\n",
    "\n",
    "def process_one_event(event_df):\n",
    "    event_df.loc[event_df[\"det\"] == 1, 'station'] = event_df.loc[event_df[\"det\"] == 1, 'station'].values + 3\n",
    "    event_df = event_df[['event','x','y','z','station','track']]\n",
    "    try:\n",
    "        event_df = transformer(event_df)\n",
    "    except AssertionError as err:\n",
    "        print(\"ASS error %r\" % err)\n",
    "        return None\n",
    "    event_df.rename(columns={'index': 'index_old'}, inplace=True)\n",
    "    preds, labels, ellipses = go_over_stations(event_df, max_n_stations=9)\n",
    "    return preds, ellipses, labels, event_df\n",
    "    #return seeds, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_empty_ellipses(x, preds, grus, mask):\n",
    "    empty_ellipses_mask = (mask.sum(axis=-1) == 0) # if nothing is found in ellipse\n",
    "    empty_ellipses = preds[empty_ellipses_mask]#.detach().cpu().numpy()\n",
    "    full_ellipses = preds[~empty_ellipses_mask]\n",
    "    empty_xs = x[empty_ellipses_mask]\n",
    "    empty_grus = grus[empty_ellipses_mask]#.detach().cpu().numpy()\n",
    "    return empty_xs, empty_ellipses, empty_grus, full_ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.enter_interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks(df, min_len=4):\n",
    "    tracks = df[df['track'] != -1].groupby('track')\n",
    "    multiplicity = tracks.ngroups\n",
    "    tracks_vs_len = {3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: []}\n",
    "    all_tracks = []\n",
    "    for i, track in tracks:\n",
    "        temp_track = track[['x', 'y', 'z']].values\n",
    "        if len(temp_track) >= min_len:\n",
    "            tracks_vs_len[len(temp_track)].append(temp_track)\n",
    "            all_tracks.append(temp_track)\n",
    "    for stations_in_track, this_track_list in tracks_vs_len.items():\n",
    "        if len(this_track_list) > 0:\n",
    "            tracks_vs_len[stations_in_track] = np.stack(this_track_list, 0)\n",
    "    return tracks_vs_len, all_tracks, multiplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(gt_tracks, predicted_tracks, use_torch=False, device='cuda'):\n",
    "    if use_torch:\n",
    "        labels_for_ellipses = torch.zeros(len(predicted_tracks), dtype=torch.bool, device=device)\n",
    "        assert len(predicted_tracks) > 0, 'Can not compute labels for empty set of tracks!'\n",
    "        if len(gt_tracks) > 0:\n",
    "            expanded_tracks = gt_tracks.unsqueeze(0).repeat((len(predicted_tracks), 1, 1, 1))\n",
    "            expanded_xs = predicted_tracks.unsqueeze(1).repeat((1, expanded_tracks.shape[1], 1,1))\n",
    "            labels_for_ellipses += torch.any(torch.all(torch.all(torch.isclose(expanded_tracks.float(), expanded_xs.float().to(device), rtol=1e-04 ), dim=-1), dim=-1),\n",
    "                                             dim=-1)\n",
    "            assert len(labels_for_ellipses) == len(expanded_xs), 'length of labels and xs is different!'\n",
    "        labels_for_ellipses_numpy = labels_for_ellipses.detach().cpu().numpy()\n",
    "        del labels_for_ellipses\n",
    "        return labels_for_ellipses_numpy\n",
    "    else:\n",
    "        labels_for_ellipses = np.zeros(len(predicted_tracks), dtype=bool)\n",
    "        assert len(predicted_tracks) > 0, 'Can not compute labels for empty set of tracks!'\n",
    "        if len(gt_tracks) > 0:\n",
    "            expanded_tracks = np.expand_dims(gt_tracks, 0).repeat(len(predicted_tracks), 0)\n",
    "            expanded_xs = np.expand_dims(predicted_tracks, 1).repeat(expanded_tracks.shape[1], 1)\n",
    "            labels_for_ellipses += np.any(\n",
    "                np.all(np.all(np.equal(expanded_tracks, expanded_xs), axis=-1),\n",
    "                       axis=-1), axis=-1)\n",
    "            assert len(labels_for_ellipses) == len(expanded_xs), 'length of labels and xs is different!'\n",
    "    return labels_for_ellipses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prolong(x, gru, nearest_hits_mask, nearest_hits, stations_gone, use_torch=False):\n",
    "    if use_torch:\n",
    "        xs_for_prolong = x.unsqueeze(1).repeat((1, nearest_hits_mask.shape[-1], 1,1))\n",
    "        grus_for_prolong = gru.unsqueeze(1)\n",
    "        grus_for_prolong = grus_for_prolong.repeat((1, nearest_hits_mask.shape[-1], 1))\n",
    "        prolonged_xs = torch.zeros((len(xs_for_prolong),\n",
    "                                    nearest_hits_mask.shape[-1],\n",
    "                                    xs_for_prolong.shape[-2] + 1,\n",
    "                                    xs_for_prolong.shape[-1]))\n",
    "        prolonged_xs[:, :, :xs_for_prolong.shape[-2], :] = xs_for_prolong\n",
    "        prolonged_xs[:, :, xs_for_prolong.shape[-2], :] = nearest_hits\n",
    "        #print(prolonged_xs.shape)\n",
    "        prolonged_xs = prolonged_xs.reshape(-1, stations_gone + 1, 3)\n",
    "        nearest_hits_mask = nearest_hits_mask.reshape(-1)\n",
    "        prolonged_xs = prolonged_xs[nearest_hits_mask]\n",
    "        prolonged_grus = grus_for_prolong.reshape(-1, grus_for_prolong.shape[-1])\n",
    "        prolonged_grus = prolonged_grus[nearest_hits_mask]\n",
    "    else:\n",
    "        xs_for_prolong = np.expand_dims(x, 1).repeat(nearest_hits_mask.shape[-1], 1)\n",
    "        grus_for_prolong = np.expand_dims(gru.detach().cpu().numpy(), 1).repeat(nearest_hits_mask.shape[-1], 1)\n",
    "        prolonged_xs = np.zeros(\n",
    "            (len(xs_for_prolong), nearest_hits_mask.shape[-1], xs_for_prolong.shape[2] + 1, 3))\n",
    "\n",
    "        prolonged_xs[:, :, :xs_for_prolong.shape[2], :] = xs_for_prolong\n",
    "        prolonged_xs[:, :, xs_for_prolong.shape[2], :] = nearest_hits\n",
    "        prolonged_xs = prolonged_xs[nearest_hits_mask].reshape(-1, stations_gone + 1, 3)\n",
    "        prolonged_grus = grus_for_prolong[nearest_hits_mask].reshape(-1,\n",
    "                                                                     grus_for_prolong.shape[-2],\n",
    "                                                                     grus_for_prolong.shape[-1])\n",
    "    return prolonged_xs, prolonged_grus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_faiss(gt_tracks, predicted_tracks, index):\n",
    "    labels_for_ellipses = np.zeros(len(predicted_tracks))\n",
    "    assert len(predicted_tracks) > 0, 'Can not compute labels for empty set of tracks!'\n",
    "    if len(gt_tracks) > 0:\n",
    "        tracks_len = gt_tracks.shape[-2]\n",
    "        gt_tracks = gt_tracks.reshape(-1, gt_tracks.shape[-1])\n",
    "        predicted_tracks = predicted_tracks.reshape(-1, gt_tracks.shape[-1])\n",
    "        gt_index = search_in_index(gt_tracks, index, 1, n_dim=3).flatten().reshape(-1, tracks_len)\n",
    "        predicted_index = search_in_index(predicted_tracks, index, 1, n_dim=3).flatten().reshape(-1, tracks_len)\n",
    "        expanded_gt = np.expand_dims(gt_index, 0).repeat(len(predicted_index), 0)\n",
    "        expanded_preds = np.expand_dims(predicted_index, 1).repeat(expanded_gt.shape[1], 1)\n",
    "        labels_for_ellipses += np.any(np.all(np.equal(expanded_gt, expanded_preds), axis=-1),axis=-1)\n",
    "        assert len(labels_for_ellipses) == len(expanded_preds), 'length of labels and xs is different!'\n",
    "    return labels_for_ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(preds, targets, grus, ellipses, index, labels,  labels_for_batch, gru_candidates, track_candidates, candidate_ellipses):\n",
    "    orig_ellipses = torch.zeros((len(ellipses), 4))\n",
    "    orig_ellipses[:, :2] = ellipses[:, :2]\n",
    "    orig_ellipses[:, 2:] = ellipses[:, 3:]\n",
    "    labels_for_ellipses = get_labels_faiss(targets,\n",
    "                                     preds.detach().cpu().numpy(), index=index)\n",
    "    labels_for_batch.append(labels_for_ellipses)\n",
    "    gru_candidates.extend(grus)  # because we need gru for predicted ellipse\n",
    "    labels.extend(labels_for_ellipses)\n",
    "    track_candidates.extend(preds)\n",
    "    candidate_ellipses.extend(orig_ellipses)\n",
    "    return labels, labels_for_batch, gru_candidates, track_candidates, candidate_ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seeds_only_real(df, columns=['x','y','z']):\n",
    "    real = df[df['track']!=-1]\n",
    "    temp1 = real[real.station == 0]\n",
    "    st0_hits = temp1[columns].values\n",
    "    temp2 = real[real.station == 1]\n",
    "    st1_hits = temp2[columns].values\n",
    "    # all possible combinations\n",
    "    seeds = np.zeros((len(temp1), 2, 3))\n",
    "    seeds[:, 0, ] = st0_hits\n",
    "    seeds[:, 1, ] = st1_hits\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seeds_only_real_one_hit(df, columns=['x','y','z']):\n",
    "    real = df[df['track']!=-1]\n",
    "    temp1 = real[real.station == 0]\n",
    "    st0_hits = temp1[columns].values\n",
    "    #temp2 = real[real.station == 1]\n",
    "    #st1_hits = temp2[columns].values\n",
    "    # all possible combinations\n",
    "    seeds = np.zeros((len(temp1), 1, 3))\n",
    "    seeds[:, 0, ] = st0_hits\n",
    "    #seeds[:, 1, ] = st1_hits\n",
    "    #print('seeds:', seeds)\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_over_stations(df, max_n_stations=9):\n",
    "    max_batch_size = 256\n",
    "    all_hits_index = build_index(df)\n",
    "    tracks_vs_len, all_tracks, multiplicity = get_tracks(df)\n",
    "    #print(tracks_vs_len)\n",
    "    #seeds, target = to_cart(df)\n",
    "    chunk_data_x = get_seeds_only_real(df)\n",
    "    #print(chunk_data_x)\n",
    "    #chunk_data_x = np.expand_dims(chunk_data_x, 1)\n",
    "    #index = build_index(target)\n",
    "    # search(target[:2], index)\n",
    "    #chunk_data_x = seeds_to_input(seeds)\n",
    "    chunk_data_len = torch.tensor(np.full(len(chunk_data_x), 2), dtype=torch.int64).to(DEVICE)\n",
    "    gru_candidates = []\n",
    "    x_candidates = []\n",
    "    candidate_labels = []\n",
    "    candidate_ellipses = []\n",
    "    for stations_gone in range(2, max_n_stations):\n",
    "        #print(f'===> {stations_gone}')\n",
    "        num_batches = int(len(chunk_data_x) / max_batch_size) + 1\n",
    "        #print(num_batches)\n",
    "        num_right_batches = 0\n",
    "        num_all_batches = 0\n",
    "        next_stage_xs = []\n",
    "        next_stage_lens = []\n",
    "        if len(chunk_data_x) == 0:\n",
    "            #print('Have zero ellipces on this station! Skipping other stations')\n",
    "            #print(candidate_ellipses)\n",
    "            #print(x_candidates)\n",
    "            #print(candidate_labels)\n",
    "            return x_candidates, candidate_labels, candidate_ellipses\n",
    "        labels_for_empty_el_batch = []\n",
    "        labels_for_full_el_batch = []\n",
    "        station_df = df[df['station']==stations_gone]\n",
    "        current_index = build_index(station_df)\n",
    "        this_station_hits = build_hits(station_df)\n",
    "        for batch_num in range(num_batches):\n",
    "            min_i = max_batch_size*batch_num\n",
    "            max_i = min(max_batch_size + min_i, len(chunk_data_x))\n",
    "            if min_i==max_i:\n",
    "                #print('Have zero ellipces on this station! Skipping other stations')\n",
    "                #print(candidate_ellipses)\n",
    "                #print(x_candidates)\n",
    "                #print(candidate_labels)\n",
    "                return x_candidates, candidate_labels, candidate_ellipses\n",
    "            \n",
    "            this_batch_x = torch.tensor(chunk_data_x[min_i: max_i]).to(DEVICE)\n",
    "            this_batch_len = chunk_data_len[min_i: max_i]\n",
    "            #print(this_batch_x)\n",
    "            batch_prediction, batch_gru = model(this_batch_x,\n",
    "                                                     torch.tensor(this_batch_len, dtype=torch.int64).to(DEVICE),\n",
    "                                                     return_gru_states=True)\n",
    "            new_pred = torch.full((len(batch_prediction), 5), z_values[stations_gone], device=DEVICE)\n",
    "            new_pred[:, :2] = batch_prediction[:, -1, :2]\n",
    "            new_pred[:, 3:] = batch_prediction[:, -1, 2:]\n",
    "            batch_prediction = new_pred\n",
    "            batch_gru = batch_gru[:, -1]\n",
    "            #if batch_num == 0:\n",
    "              #  print(f'station {stations_gone+1}, on this station: {len(this_station_hits)} hits' )\n",
    "            if len(this_station_hits) == 0:\n",
    "            #    LOGGER.info('Have zero hits on this station! Skipping other stations')\n",
    "            #    print(candidate_ellipses)\n",
    "            #    print(x_candidates)\n",
    "            #    print(candidate_labels)\n",
    "                return x_candidates, candidate_labels, candidate_ellipses\n",
    "            prediction_numpy = batch_prediction.detach().cpu().numpy()\n",
    "            nearest_hits_index = search_in_index(prediction_numpy[:, :3],\n",
    "                                                 current_index, \n",
    "                                                 30,\n",
    "                                                 n_dim=3)\n",
    "            nearest_hits = this_station_hits[nearest_hits_index]\n",
    "            nearest_hits, in_ellipse_mask = filter_hits_in_ellipses(prediction_numpy,\n",
    "                                                               nearest_hits,\n",
    "                                                               nearest_hits_index,\n",
    "                                                               filter_station=False,\n",
    "                                                               z_last=True,\n",
    "                                                               find_n=nearest_hits_index.shape[1])\n",
    "            nearest_hits = torch.from_numpy(nearest_hits)\n",
    "            nearest_hits_mask = in_ellipse_mask \n",
    "            # here empty ellipses and all inputs for them are saved\n",
    "            empty_xs, empty_ellipses, empty_grus, predicted_ellipses = get_data_for_empty_ellipses(this_batch_x, \n",
    "                                                                               batch_prediction, \n",
    "                                                                               batch_gru, \n",
    "                                                                               nearest_hits_mask)\n",
    "            prolonged_batch_xs, prolonged_grus = prolong(this_batch_x,\n",
    "                                                         batch_gru,\n",
    "                                                         nearest_hits_mask,\n",
    "                                                         nearest_hits,\n",
    "                                                         stations_gone,\n",
    "                                                         use_torch=True)\n",
    "            next_stage_xs.append(prolonged_batch_xs)\n",
    "            next_stage_lens.append(np.full(len(prolonged_batch_xs), stations_gone + 1))\n",
    "            if stations_gone > 3:\n",
    "                use_empty_ellipses = []\n",
    "                empty_ellipses_station_intersections = []\n",
    "                use_empty_ellipses = torch.ones(len(empty_ellipses), dtype=torch.bool)\n",
    "                empty_xs = empty_xs[use_empty_ellipses]\n",
    "                empty_grus = empty_grus[use_empty_ellipses]\n",
    "                if len(empty_xs) > 0:\n",
    "                    (candidate_labels, \n",
    "                     labels_for_empty_el_batch, \n",
    "                     gru_candidates, \n",
    "                     x_candidates,\n",
    "                     candidate_ellipses) =  get_candidates(empty_xs, \n",
    "                                                     tracks_vs_len[stations_gone],\n",
    "                                                     prolonged_grus[:, -2], \n",
    "                                                     empty_ellipses,\n",
    "                                                     all_hits_index,\n",
    "                                                     candidate_labels, \n",
    "                                                     labels_for_full_el_batch, \n",
    "                                                     gru_candidates, \n",
    "                                                     x_candidates,\n",
    "                                                     candidate_ellipses)\n",
    "                    #print(candidate_ellipses)\n",
    "            if (stations_gone == (max_n_stations-1)): # if we are predicting for last station\n",
    "                if len(prolonged_batch_xs) > 0:  # now we prolong candidates with all hits *in* ellipses\n",
    "                    (candidate_labels,\n",
    "                     labels_for_full_el_batch, \n",
    "                     gru_candidates, \n",
    "                     x_candidates,\n",
    "                     candidate_ellipses) =  get_candidates(prolonged_batch_xs, \n",
    "                                                     tracks_vs_len[stations_gone + 1],\n",
    "                                                     prolonged_grus[:, -1], \n",
    "                                                     predicted_ellipses,\n",
    "                                                     all_hits_index,\n",
    "                                                     candidate_labels, \n",
    "                                                     labels_for_full_el_batch, \n",
    "                                                     gru_candidates, \n",
    "                                                     x_candidates,\n",
    "                                                     candidate_ellipses)\n",
    "                    \n",
    "        if len(next_stage_xs) > 1:\n",
    "            chunk_data_x = np.concatenate(next_stage_xs, 0)\n",
    "            chunk_data_len = np.concatenate(next_stage_lens, 0)\n",
    "        else:\n",
    "            try:\n",
    "                chunk_data_x = next_stage_xs[0]\n",
    "                chunk_data_len = next_stage_lens[0]\n",
    "            except:\n",
    "                continue\n",
    "    return x_candidates, candidate_labels, candidate_ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_event = df[df.event == 0]\n",
    "preds, ellipses, labels, event_df = process_one_event(one_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency for  event 0 (mult = 15): 0.7333333333333333\n",
      "Efficiency for  event 1 (mult = 4): 1.0\n",
      "Efficiency for  event 2 (mult = 4): 1.0\n",
      "Efficiency for  event 5 (mult = 9): 1.0\n",
      "Efficiency for  event 6 (mult = 1): 1.0\n",
      "Efficiency for  event 7 (mult = 15): 0.8666666666666667\n",
      "Efficiency for  event 8 (mult = 15): 0.26666666666666666\n",
      "Efficiency for  event 9 (mult = 14): 0.2857142857142857\n",
      "Efficiency for  event 10 (mult = 10): 0.9\n",
      "Efficiency for  event 11 (mult = 10): 0.6\n",
      "Efficiency for  event 12 (mult = 18): 0.5\n",
      "Efficiency for  event 13 (mult = 2): 1.0\n",
      "Efficiency for  event 15 (mult = 6): 0.6666666666666666\n",
      "Efficiency for  event 16 (mult = 14): 0.5\n",
      "Efficiency for  event 17 (mult = 7): 0.5714285714285714\n",
      "Efficiency for  event 18 (mult = 12): 0.9166666666666666\n",
      "Efficiency for  event 19 (mult = 7): 0.8571428571428571\n",
      "Efficiency for  event 20 (mult = 4): 0.5\n",
      "Efficiency for  event 21 (mult = 10): 0.6\n",
      "Efficiency for  event 24 (mult = 1): 1.0\n",
      "Efficiency for  event 25 (mult = 10): 1.0\n",
      "Efficiency for  event 27 (mult = 14): 0.7857142857142857\n",
      "Efficiency for  event 28 (mult = 12): 0.8333333333333334\n",
      "Efficiency for  event 29 (mult = 9): 0.3333333333333333\n",
      "Efficiency for  event 30 (mult = 2): 1.0\n",
      "Efficiency for  event 31 (mult = 2): 1.0\n",
      "Efficiency for  event 32 (mult = 12): 0.5\n",
      "Efficiency for  event 33 (mult = 4): 1.0\n",
      "Efficiency for  event 34 (mult = 1): 1.0\n",
      "Efficiency for  event 35 (mult = 3): 1.0\n",
      "Efficiency for  event 36 (mult = 15): 0.8\n",
      "Efficiency for  event 37 (mult = 4): 1.0\n",
      "Efficiency for  event 39 (mult = 10): 0.3\n",
      "Efficiency for  event 40 (mult = 5): 0.4\n",
      "Efficiency for  event 41 (mult = 1): 1.0\n",
      "Efficiency for  event 43 (mult = 14): 0.7857142857142857\n",
      "Efficiency for  event 44 (mult = 4): 0.25\n",
      "Efficiency for  event 46 (mult = 7): 0.5714285714285714\n",
      "Efficiency for  event 49 (mult = 2): 1.0\n",
      "Efficiency for  event 50 (mult = 5): 0.8\n",
      "Efficiency for  event 51 (mult = 12): 0.5\n",
      "Efficiency for  event 53 (mult = 16): 0.125\n",
      "Efficiency for  event 54 (mult = 14): 0.5714285714285714\n",
      "Efficiency for  event 56 (mult = 8): 0.375\n",
      "Efficiency for  event 58 (mult = 5): 0.4\n",
      "Efficiency for  event 59 (mult = 4): 1.0\n",
      "Efficiency for  event 60 (mult = 2): 1.0\n",
      "Efficiency for  event 61 (mult = 3): 1.0\n",
      "Efficiency for  event 62 (mult = 13): 0.07692307692307693\n",
      "Efficiency for  event 63 (mult = 3): 1.0\n",
      "Efficiency for  event 64 (mult = 5): 1.0\n",
      "Efficiency for  event 65 (mult = 12): 0.9166666666666666\n",
      "Efficiency for  event 66 (mult = 3): 1.0\n",
      "Efficiency for  event 68 (mult = 8): 0.75\n",
      "Efficiency for  event 69 (mult = 12): 1.0\n",
      "Efficiency for  event 70 (mult = 7): 1.0\n",
      "Efficiency for  event 71 (mult = 2): 1.0\n",
      "Efficiency for  event 72 (mult = 9): 0.4444444444444444\n",
      "Efficiency for  event 73 (mult = 10): 0.9\n",
      "Efficiency for  event 74 (mult = 1): 1.0\n",
      "Efficiency for  event 75 (mult = 2): 1.0\n",
      "Efficiency for  event 77 (mult = 13): 0.7692307692307693\n",
      "Efficiency for  event 78 (mult = 3): 1.0\n",
      "Efficiency for  event 79 (mult = 1): 0.0\n",
      "Efficiency for  event 80 (mult = 10): 0.3\n",
      "Efficiency for  event 81 (mult = 1): 1.0\n",
      "Efficiency for  event 82 (mult = 2): 1.0\n",
      "Efficiency for  event 83 (mult = 8): 0.625\n",
      "Efficiency for  event 84 (mult = 10): 0.8\n",
      "Efficiency for  event 85 (mult = 1): 1.0\n",
      "Efficiency for  event 86 (mult = 6): 1.0\n",
      "Efficiency for  event 87 (mult = 1): 1.0\n",
      "Efficiency for  event 88 (mult = 8): 0.625\n",
      "Efficiency for  event 89 (mult = 2): 1.0\n",
      "Efficiency for  event 90 (mult = 5): 1.0\n",
      "Efficiency for  event 91 (mult = 5): 1.0\n",
      "Efficiency for  event 92 (mult = 4): 1.0\n",
      "Efficiency for  event 93 (mult = 4): 1.0\n",
      "Efficiency for  event 94 (mult = 14): 0.9285714285714286\n",
      "Efficiency for  event 95 (mult = 2): 1.0\n",
      "Efficiency for  event 96 (mult = 15): 1.0\n",
      "Efficiency for  event 97 (mult = 16): 0.0625\n",
      "Efficiency for  event 98 (mult = 7): 0.8571428571428571\n",
      "Efficiency for  event 100 (mult = 1): 1.0\n",
      "Efficiency for  event 101 (mult = 5): 0.6\n",
      "Efficiency for  event 102 (mult = 2): 1.0\n",
      "Efficiency for  event 103 (mult = 9): 1.0\n",
      "Efficiency for  event 104 (mult = 15): 0.2\n",
      "Efficiency for  event 105 (mult = 1): 1.0\n",
      "Efficiency for  event 106 (mult = 12): 0.5833333333333334\n",
      "Efficiency for  event 108 (mult = 2): 1.0\n",
      "Efficiency for  event 109 (mult = 7): 0.5714285714285714\n",
      "Efficiency for  event 110 (mult = 3): 0.3333333333333333\n",
      "Efficiency for  event 111 (mult = 1): 1.0\n",
      "Efficiency for  event 112 (mult = 13): 0.46153846153846156\n",
      "Efficiency for  event 113 (mult = 4): 1.0\n",
      "Efficiency for  event 114 (mult = 3): 1.0\n",
      "Efficiency for  event 115 (mult = 16): 0.875\n",
      "Efficiency for  event 116 (mult = 1): 0.0\n",
      "Efficiency for  event 117 (mult = 4): 1.0\n",
      "Efficiency for  event 118 (mult = 3): 1.0\n",
      "Efficiency for  event 119 (mult = 1): 1.0\n",
      "Efficiency for  event 120 (mult = 7): 1.0\n",
      "Efficiency for  event 121 (mult = 1): 1.0\n",
      "Efficiency for  event 122 (mult = 2): 1.0\n",
      "Efficiency for  event 123 (mult = 2): 0.0\n",
      "Efficiency for  event 124 (mult = 7): 0.8571428571428571\n",
      "Efficiency for  event 125 (mult = 18): 0.05555555555555555\n",
      "Efficiency for  event 126 (mult = 8): 0.625\n",
      "Efficiency for  event 127 (mult = 16): 0.4375\n",
      "Efficiency for  event 128 (mult = 1): 1.0\n",
      "Efficiency for  event 129 (mult = 1): 1.0\n",
      "Efficiency for  event 131 (mult = 16): 0.5\n",
      "Efficiency for  event 132 (mult = 15): 0.13333333333333333\n",
      "Efficiency for  event 134 (mult = 4): 1.0\n",
      "Efficiency for  event 135 (mult = 6): 1.0\n",
      "Efficiency for  event 136 (mult = 8): 0.5\n",
      "Efficiency for  event 137 (mult = 22): 0.45454545454545453\n",
      "Efficiency for  event 138 (mult = 7): 0.42857142857142855\n",
      "Efficiency for  event 139 (mult = 10): 0.9\n",
      "Efficiency for  event 140 (mult = 2): 1.0\n",
      "Efficiency for  event 141 (mult = 10): 0.8\n",
      "Efficiency for  event 142 (mult = 1): 0.0\n",
      "Efficiency for  event 143 (mult = 1): 1.0\n",
      "Efficiency for  event 144 (mult = 2): 0.0\n",
      "Efficiency for  event 145 (mult = 3): 0.6666666666666666\n",
      "Efficiency for  event 147 (mult = 1): 1.0\n",
      "Efficiency for  event 149 (mult = 2): 1.0\n",
      "Efficiency for  event 150 (mult = 1): 1.0\n",
      "Efficiency for  event 151 (mult = 5): 1.0\n",
      "Efficiency for  event 152 (mult = 1): 1.0\n",
      "Efficiency for  event 153 (mult = 7): 0.8571428571428571\n",
      "Efficiency for  event 154 (mult = 3): 1.0\n",
      "Efficiency for  event 155 (mult = 2): 1.0\n",
      "Efficiency for  event 156 (mult = 2): 1.0\n",
      "Efficiency for  event 157 (mult = 12): 0.5\n",
      "Efficiency for  event 158 (mult = 10): 0.4\n",
      "Efficiency for  event 159 (mult = 14): 0.9285714285714286\n",
      "Efficiency for  event 160 (mult = 2): 1.0\n",
      "Efficiency for  event 161 (mult = 6): 1.0\n",
      "Efficiency for  event 162 (mult = 3): 1.0\n",
      "Efficiency for  event 163 (mult = 21): 0.38095238095238093\n",
      "Efficiency for  event 165 (mult = 1): 1.0\n",
      "Efficiency for  event 166 (mult = 12): 0.8333333333333334\n",
      "Efficiency for  event 167 (mult = 2): 0.0\n",
      "Efficiency for  event 168 (mult = 13): 0.5384615384615384\n",
      "Efficiency for  event 169 (mult = 14): 0.8571428571428571\n",
      "Efficiency for  event 170 (mult = 15): 0.9333333333333333\n",
      "Efficiency for  event 171 (mult = 14): 0.7857142857142857\n",
      "Efficiency for  event 172 (mult = 11): 0.8181818181818182\n",
      "Efficiency for  event 173 (mult = 2): 1.0\n",
      "Efficiency for  event 174 (mult = 1): 1.0\n",
      "Efficiency for  event 175 (mult = 4): 0.25\n",
      "Efficiency for  event 177 (mult = 21): 0.47619047619047616\n",
      "Efficiency for  event 178 (mult = 10): 0.9\n",
      "Efficiency for  event 179 (mult = 11): 0.18181818181818182\n",
      "Efficiency for  event 180 (mult = 12): 0.9166666666666666\n",
      "Efficiency for  event 181 (mult = 15): 0.8\n",
      "Efficiency for  event 182 (mult = 1): 1.0\n",
      "Efficiency for  event 183 (mult = 1): 1.0\n",
      "Efficiency for  event 184 (mult = 4): 0.25\n",
      "Efficiency for  event 185 (mult = 17): 0.47058823529411764\n",
      "Efficiency for  event 186 (mult = 6): 0.6666666666666666\n",
      "Efficiency for  event 188 (mult = 5): 1.0\n",
      "Efficiency for  event 189 (mult = 1): 1.0\n",
      "Efficiency for  event 190 (mult = 17): 0.7647058823529411\n",
      "Efficiency for  event 191 (mult = 2): 1.0\n",
      "Efficiency for  event 192 (mult = 11): 0.36363636363636365\n",
      "Efficiency for  event 194 (mult = 14): 0.8571428571428571\n",
      "Efficiency for  event 195 (mult = 12): 0.9166666666666666\n",
      "Efficiency for  event 196 (mult = 5): 1.0\n",
      "Efficiency for  event 197 (mult = 2): 1.0\n",
      "Efficiency for  event 198 (mult = 9): 1.0\n",
      "Efficiency for  event 200 (mult = 2): 1.0\n",
      "Efficiency for  event 202 (mult = 6): 1.0\n",
      "Efficiency for  event 205 (mult = 1): 1.0\n",
      "Efficiency for  event 206 (mult = 3): 1.0\n",
      "Efficiency for  event 207 (mult = 5): 0.4\n",
      "Efficiency for  event 209 (mult = 11): 1.0\n",
      "Efficiency for  event 210 (mult = 4): 1.0\n",
      "Efficiency for  event 211 (mult = 1): 1.0\n",
      "Efficiency for  event 212 (mult = 7): 0.42857142857142855\n",
      "Efficiency for  event 213 (mult = 3): 1.0\n",
      "Efficiency for  event 214 (mult = 7): 1.0\n",
      "Efficiency for  event 216 (mult = 4): 1.0\n",
      "Efficiency for  event 217 (mult = 2): 1.0\n",
      "Efficiency for  event 218 (mult = 4): 0.5\n",
      "Efficiency for  event 219 (mult = 12): 0.08333333333333333\n",
      "Efficiency for  event 220 (mult = 4): 1.0\n",
      "Efficiency for  event 221 (mult = 13): 0.3076923076923077\n",
      "Efficiency for  event 222 (mult = 4): 1.0\n",
      "Efficiency for  event 223 (mult = 9): 0.5555555555555556\n",
      "Efficiency for  event 224 (mult = 9): 0.6666666666666666\n",
      "Efficiency for  event 225 (mult = 7): 0.2857142857142857\n",
      "Efficiency for  event 226 (mult = 11): 0.8181818181818182\n",
      "Efficiency for  event 227 (mult = 10): 1.0\n",
      "Efficiency for  event 228 (mult = 14): 1.0\n",
      "Efficiency for  event 231 (mult = 1): 1.0\n",
      "Efficiency for  event 232 (mult = 12): 0.75\n",
      "Efficiency for  event 233 (mult = 17): 0.5882352941176471\n",
      "Efficiency for  event 234 (mult = 3): 1.0\n",
      "Efficiency for  event 235 (mult = 3): 1.0\n",
      "Efficiency for  event 236 (mult = 14): 0.35714285714285715\n",
      "Efficiency for  event 238 (mult = 2): 1.0\n",
      "Efficiency for  event 239 (mult = 4): 1.0\n",
      "Efficiency for  event 240 (mult = 1): 1.0\n",
      "Efficiency for  event 241 (mult = 2): 1.0\n",
      "Efficiency for  event 242 (mult = 1): 1.0\n",
      "Efficiency for  event 245 (mult = 3): 0.3333333333333333\n",
      "Efficiency for  event 246 (mult = 15): 1.0\n",
      "Efficiency for  event 247 (mult = 3): 1.0\n",
      "Efficiency for  event 248 (mult = 7): 1.0\n",
      "Efficiency for  event 249 (mult = 15): 0.8666666666666667\n",
      "Efficiency for  event 250 (mult = 5): 0.8\n",
      "Efficiency for  event 251 (mult = 2): 1.0\n",
      "Efficiency for  event 252 (mult = 8): 0.25\n",
      "Efficiency for  event 253 (mult = 7): 0.8571428571428571\n",
      "Efficiency for  event 255 (mult = 1): 1.0\n",
      "Efficiency for  event 256 (mult = 9): 1.0\n",
      "Efficiency for  event 257 (mult = 16): 0.25\n",
      "Efficiency for  event 259 (mult = 10): 0.4\n",
      "Efficiency for  event 261 (mult = 3): 0.6666666666666666\n",
      "Efficiency for  event 262 (mult = 4): 1.0\n",
      "Efficiency for  event 263 (mult = 2): 1.0\n",
      "Efficiency for  event 264 (mult = 2): 1.0\n",
      "Efficiency for  event 266 (mult = 3): 1.0\n",
      "Efficiency for  event 267 (mult = 6): 0.5\n",
      "Efficiency for  event 268 (mult = 3): 0.6666666666666666\n",
      "Efficiency for  event 269 (mult = 9): 0.3333333333333333\n",
      "Efficiency for  event 270 (mult = 7): 0.5714285714285714\n",
      "Efficiency for  event 272 (mult = 5): 1.0\n",
      "Efficiency for  event 274 (mult = 6): 0.6666666666666666\n",
      "Efficiency for  event 275 (mult = 1): 1.0\n",
      "Efficiency for  event 276 (mult = 14): 0.9285714285714286\n",
      "Efficiency for  event 277 (mult = 4): 1.0\n",
      "Efficiency for  event 278 (mult = 19): 0.10526315789473684\n",
      "Efficiency for  event 279 (mult = 11): 0.6363636363636364\n",
      "Efficiency for  event 281 (mult = 20): 0.35\n",
      "Efficiency for  event 282 (mult = 4): 1.0\n",
      "Efficiency for  event 283 (mult = 3): 0.6666666666666666\n",
      "Efficiency for  event 285 (mult = 2): 1.0\n",
      "Efficiency for  event 286 (mult = 3): 1.0\n",
      "Efficiency for  event 287 (mult = 11): 0.5454545454545454\n",
      "Efficiency for  event 288 (mult = 7): 0.8571428571428571\n",
      "Efficiency for  event 289 (mult = 8): 0.5\n",
      "Efficiency for  event 291 (mult = 2): 1.0\n",
      "Efficiency for  event 292 (mult = 9): 1.0\n",
      "Efficiency for  event 293 (mult = 11): 0.0\n",
      "Efficiency for  event 294 (mult = 14): 1.0\n",
      "Efficiency for  event 295 (mult = 13): 0.7692307692307693\n",
      "Efficiency for  event 297 (mult = 1): 1.0\n",
      "Efficiency for  event 298 (mult = 11): 0.8181818181818182\n",
      "Efficiency for  event 299 (mult = 18): 0.3888888888888889\n",
      "Mean efficiency: 0.7677839693288977\n"
     ]
    }
   ],
   "source": [
    "eff_list = []\n",
    "num_events = 300\n",
    "for i in range(num_events):\n",
    "    one_event = df[df.event == i]\n",
    "    preds, ellipses, labels, event_df = process_one_event(one_event)\n",
    "    mult = event_df[event_df.track!=-1].groupby('track').ngroups\n",
    "    if mult > 0:\n",
    "         eff_list.append(sum(labels) / mult)\n",
    "         print(f'Efficiency for  event {i} (mult = {mult}): { eff_list[-1]}')\n",
    "print(f'Mean efficiency: {np.mean(eff_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df(preds, labels, event_df):\n",
    "    #test version, need to rewrite\n",
    "    \n",
    "    curr_event = event_df.event[0]\n",
    "    sorted_event_df = event_df[event_df.track != -1].sort_values(['track', 'station'])\n",
    "    sorted_event_df = sorted_event_df.drop(['x', 'y', 'z', 'event'], axis='columns')\n",
    "    \n",
    "    n_stations = 9\n",
    "    new_columns = ['event', *[f'hit_id_{i}' for i in range(n_stations)]]\n",
    "    new_df = pd.DataFrame(columns=new_columns)\n",
    "    \n",
    "    track_indexes = sorted_event_df.track.unique()\n",
    "    \n",
    "    for idx, track_id in enumerate(track_indexes):\n",
    "        track_hits = sorted_event_df[sorted_event_df.track == track_id].index_old\n",
    "        to_pad = n_stations - len(track_hits)\n",
    "        padded_hits = np.pad(track_hits, (1, to_pad), constant_values=(curr_event, -1)) #adding event id to beginning\n",
    "        new_df.loc[track_id] = padded_hits\n",
    "        \n",
    "    preds = np.array(preds)\n",
    "    filtered_preds = preds[np.array(labels) == 1]\n",
    "    track_ids = []\n",
    "    \n",
    "    for pred in filtered_preds:\n",
    "        #checks first hit of pred and track are equal\n",
    "        tmp = (pred[0].numpy() == event_df[event_df.track != -1][['x', 'y', 'z']].astype('float32')).all(1).argmax()\n",
    "        track_ids.append(event_df[event_df.track != -1].track[tmp])\n",
    "    return new_df.loc[track_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>hit_id_0</th>\n",
       "      <th>hit_id_1</th>\n",
       "      <th>hit_id_2</th>\n",
       "      <th>hit_id_3</th>\n",
       "      <th>hit_id_4</th>\n",
       "      <th>hit_id_5</th>\n",
       "      <th>hit_id_6</th>\n",
       "      <th>hit_id_7</th>\n",
       "      <th>hit_id_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>194</td>\n",
       "      <td>129567</td>\n",
       "      <td>129668</td>\n",
       "      <td>129806</td>\n",
       "      <td>130019</td>\n",
       "      <td>130445</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>194</td>\n",
       "      <td>129542</td>\n",
       "      <td>129635</td>\n",
       "      <td>129774</td>\n",
       "      <td>129954</td>\n",
       "      <td>130394</td>\n",
       "      <td>130475</td>\n",
       "      <td>130676</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>194</td>\n",
       "      <td>129572</td>\n",
       "      <td>129680</td>\n",
       "      <td>129786</td>\n",
       "      <td>129990</td>\n",
       "      <td>130435</td>\n",
       "      <td>130652</td>\n",
       "      <td>130706</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>194</td>\n",
       "      <td>129547</td>\n",
       "      <td>129639</td>\n",
       "      <td>129775</td>\n",
       "      <td>129959</td>\n",
       "      <td>130389</td>\n",
       "      <td>130508</td>\n",
       "      <td>130698</td>\n",
       "      <td>131129</td>\n",
       "      <td>131156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>194</td>\n",
       "      <td>129548</td>\n",
       "      <td>129640</td>\n",
       "      <td>129777</td>\n",
       "      <td>129960</td>\n",
       "      <td>130384</td>\n",
       "      <td>130470</td>\n",
       "      <td>130685</td>\n",
       "      <td>131124</td>\n",
       "      <td>131158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>194</td>\n",
       "      <td>129554</td>\n",
       "      <td>129654</td>\n",
       "      <td>129789</td>\n",
       "      <td>129967</td>\n",
       "      <td>130380</td>\n",
       "      <td>130468</td>\n",
       "      <td>130692</td>\n",
       "      <td>131131</td>\n",
       "      <td>131150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>194</td>\n",
       "      <td>129557</td>\n",
       "      <td>129656</td>\n",
       "      <td>129790</td>\n",
       "      <td>129978</td>\n",
       "      <td>130373</td>\n",
       "      <td>130506</td>\n",
       "      <td>130700</td>\n",
       "      <td>131137</td>\n",
       "      <td>131163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>194</td>\n",
       "      <td>129558</td>\n",
       "      <td>129657</td>\n",
       "      <td>129791</td>\n",
       "      <td>129974</td>\n",
       "      <td>130379</td>\n",
       "      <td>130507</td>\n",
       "      <td>130699</td>\n",
       "      <td>131138</td>\n",
       "      <td>131161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>194</td>\n",
       "      <td>129559</td>\n",
       "      <td>129658</td>\n",
       "      <td>129792</td>\n",
       "      <td>129985</td>\n",
       "      <td>130370</td>\n",
       "      <td>130505</td>\n",
       "      <td>130701</td>\n",
       "      <td>131136</td>\n",
       "      <td>131167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>194</td>\n",
       "      <td>129562</td>\n",
       "      <td>129659</td>\n",
       "      <td>129794</td>\n",
       "      <td>129987</td>\n",
       "      <td>130070</td>\n",
       "      <td>130465</td>\n",
       "      <td>130696</td>\n",
       "      <td>131121</td>\n",
       "      <td>131166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>194</td>\n",
       "      <td>129580</td>\n",
       "      <td>129740</td>\n",
       "      <td>129803</td>\n",
       "      <td>130025</td>\n",
       "      <td>130462</td>\n",
       "      <td>130663</td>\n",
       "      <td>130711</td>\n",
       "      <td>131142</td>\n",
       "      <td>131173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>194</td>\n",
       "      <td>129582</td>\n",
       "      <td>129742</td>\n",
       "      <td>129804</td>\n",
       "      <td>130024</td>\n",
       "      <td>130463</td>\n",
       "      <td>130620</td>\n",
       "      <td>130705</td>\n",
       "      <td>131144</td>\n",
       "      <td>131169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    event hit_id_0 hit_id_1 hit_id_2 hit_id_3 hit_id_4 hit_id_5 hit_id_6  \\\n",
       "225   194   129567   129668   129806   130019   130445       -1       -1   \n",
       "448   194   129542   129635   129774   129954   130394   130475   130676   \n",
       "77    194   129572   129680   129786   129990   130435   130652   130706   \n",
       "133   194   129547   129639   129775   129959   130389   130508   130698   \n",
       "178   194   129548   129640   129777   129960   130384   130470   130685   \n",
       "217   194   129554   129654   129789   129967   130380   130468   130692   \n",
       "183   194   129557   129656   129790   129978   130373   130506   130700   \n",
       "447   194   129558   129657   129791   129974   130379   130507   130699   \n",
       "9     194   129559   129658   129792   129985   130370   130505   130701   \n",
       "221   194   129562   129659   129794   129987   130070   130465   130696   \n",
       "49    194   129580   129740   129803   130025   130462   130663   130711   \n",
       "54    194   129582   129742   129804   130024   130463   130620   130705   \n",
       "\n",
       "    hit_id_7 hit_id_8  \n",
       "225       -1       -1  \n",
       "448       -1       -1  \n",
       "77        -1       -1  \n",
       "133   131129   131156  \n",
       "178   131124   131158  \n",
       "217   131131   131150  \n",
       "183   131137   131163  \n",
       "447   131138   131161  \n",
       "9     131136   131167  \n",
       "221   131121   131166  \n",
       "49    131142   131173  \n",
       "54    131144   131169  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_event = df[df.event == 194]\n",
    "preds, ellipses, labels, event_df = process_one_event(one_event)\n",
    "build_df(preds, labels, event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariadne_gpu_kernel",
   "language": "python",
   "name": "ariadne_gpu_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
