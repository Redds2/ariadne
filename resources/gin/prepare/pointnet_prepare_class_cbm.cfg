preprocess.target_processor = @PointNet_ProcessorCBM
preprocess.output_dir = 'output/cbm_points_10_full_points'
preprocess.ignore_asserts = True
preprocess.chunk_length = 4
preprocess.cpu_count = 3

#parse.input_file_mask='data_cbm/hits14/*.txt'
parse.input_file_mask='data_cbm/hits14/*.txt'
parse.csv_params={
                    "sep": '\s+',
                    #"nrows": 100000,
                    "encoding": 'utf-8',
                    "names":  ['event',  'ntrack',  'det', 'station','side', 'z', 'y', 'x', 'time','dX', 'dY', 'dZ', 'dTime']
                 }

### events_quantity:
# '1..10' (list of events with these indexes)
# or ':' (all events from df)
# or single index '3'
parse.events_quantity = ':'

# preprocessor
PointNet_ProcessorCBM.transforms = [  @ConstraintsNormalize() ]
PointNet_ProcessorCBM.coord_cols = ['x', 'y', 'z']
PointNet_ProcessorCBM.stats_cols = ['x', 'y', 'z', 'ntrack']
PointNet_ProcessorCBM.det_indices = [(0,12), (1,3), (2,0)]
PointNet_ProcessorCBM.with_random_sort = True
PointNet_ProcessorCBM.forward_fields = ['maxis', 'minis', 'mean_hits',]
PointNet_ProcessorCBM.with_balance = True

#### transformations
ConstraintsNormalize.use_global_constraints = True
ConstraintsNormalize.columns=('x', 'y', 'z')
#ConstraintsNormalize.constraints = {
#    'r': [0, 96.0], 'phi': [-3.15, 3.15], 'z': [11.97, 183.82]
#}
#ConstraintsNormalize.mode = 'positive'
ConstraintsNormalize.constraints = {
    'x': [-440., 440.], 'y': [-610., 610.], 'z': [189., 868]
}

# ToCylindrical.cart_columns = ('y', 'x')
#ToCylindrical.drop_old = True
