preprocess.target_processor = @TrackNetV2_1_Processor
preprocess.output_dir = 'output/cgem_t_tracknet_2_1'
preprocess.ignore_asserts = True

parse.input_file_mask='data/new_data/*_class.txt'
parse.csv_params={
                    "sep": '\s+',
                    #"nrows": 1000,
                    "encoding": 'utf-8',
                    "names":  ['event',  'x', 'y', 'z', 'station',
                               'track', 'px', 'py', 'pz', 'X0', 'Y0', 'Z0']
                 }

### events_quantity:
# ['1..10'] (list of events with these indexes)
# or [':'] (all events from df)
# or single index ['3']
parse.events_quantity = '0..5000'
TrackNetV2_1_Processor.name_suffix = 'tracknet_v2_19_13_undersampled'
TrackNetV2_1_Processor.n_times_oversampling = 10
TrackNetV2_1_Processor.valid_size = 0.3
TrackNetV2_1_Processor.device = 'cpu'
TrackNetV2_1_Processor.tracknet_v2_model = @TrackNETv2
TrackNetV2_1_Processor.tracknet_v2_checkpoint = 'lightning_logs/TrackNETv2/version_0/_epoch=29-step=29.ckpt'
TrackNetV2_1_Processor.transforms = [
    @DropSpinningTracks(),
    @DropShort(),
    @ToCylindrical(),
    @ConstraintsNormalize()
]

### tracknet model
TrackNETv2.input_features = 3
TrackNETv2.conv_features = 32
TrackNETv2.rnn_type = 'gru'
TrackNETv2.batch_first = True

#### transformations
ConstraintsNormalize.use_global_constraints = True
ConstraintsNormalize.columns=('r', 'phi', 'z')
ConstraintsNormalize.constraints = {
    'r': [80., 167.], 'phi': [-3.15, 3.15], 'z': [-423.5, 423.5]
}
